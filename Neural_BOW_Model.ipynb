{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in /home/sharadv/anaconda3/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (1.14.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (1.0.9)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (3.12)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (1.0.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (1.11.0)\n",
      "Requirement already satisfied: h5py in /home/sharadv/anaconda3/lib/python3.6/site-packages (from Keras) (2.7.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharadv/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "#import dill as pkl\n",
    "import pickle as pkl\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "#import nltk\n",
    "#import re\n",
    "import itertools\n",
    "#import unittest\n",
    "#import RegexTester\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#import nltk\n",
    "#from nltk.corpus import wordnet\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "#from keras.optimizers import SGD\n",
    "\n",
    "#from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model, load_model, Sequential\n",
    "#from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers, regularizers, optimizers\n",
    "#from keras.callbacks import History, CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, average_precision_score, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD Pre-processed DATA from Analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_pickle(\"./full_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(full_data, test_size=0.10, random_state=42)\n",
    "\n",
    "#Separate training set into train and dev. Roughly 80% of original data is train, 10% dev, 10% test\n",
    "train_set, dev_set = train_test_split(train_set, test_size=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling algorithm - multi-label splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(df, max_records = 10):\n",
    "    max_per_genre = int(max_records/10)\n",
    "    new_df = pd.DataFrame(columns=list(df.columns))\n",
    "    genre_count = defaultdict(int)\n",
    "    record_count = 0\n",
    "    while record_count < max_records:\n",
    "        counter = 0\n",
    "        sample = df.sample(1, replace = True)\n",
    "        for i in list(itertools.chain(*sample[\"list_genres_consol\"])):\n",
    "            if genre_count[i] == max_per_genre:\n",
    "                df = df[~df[\"list_genres_consol\"].apply(lambda x: str(i) in x)]\n",
    "                continue\n",
    "            else:\n",
    "                counter += 1\n",
    "        if counter == len(sample[\"list_genres_consol\"]):\n",
    "            new_df = new_df.append(sample)\n",
    "            record_count += 1\n",
    "            for i in list(itertools.chain(*sample[\"list_genres_consol\"])):\n",
    "                genre_count[i] += 1\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate sample\n",
    "start = time.time()\n",
    "sample_df = oversample(train_set, max_records=50000)\n",
    "end = time.time()\n",
    "print(\"Duration in seconds: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = defaultdict(int)\n",
    "\n",
    "def count_genres(row):\n",
    "    for i in row: \n",
    "        sample_count[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.00% of the movies are Comedy\n",
      "10.00% of the movies are Drama\n",
      "10.00% of the movies are Thriller\n",
      "10.00% of the movies are Adventure\n",
      "10.00% of the movies are Sci-Fi\n",
      "10.00% of the movies are Horror\n",
      "10.00% of the movies are Family\n",
      "10.00% of the movies are Action\n",
      "10.00% of the movies are Crime\n",
      "10.00% of the movies are Romance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0,0,'Comedy'),\n",
       " Text(0,0,'Drama'),\n",
       " Text(0,0,'Thriller'),\n",
       " Text(0,0,'Adventure'),\n",
       " Text(0,0,'Sci-Fi'),\n",
       " Text(0,0,'Horror'),\n",
       " Text(0,0,'Family'),\n",
       " Text(0,0,'Action'),\n",
       " Text(0,0,'Crime'),\n",
       " Text(0,0,'Romance')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_df[\"list_genres_consol\"].apply(lambda row: count_genres(row))\n",
    "\n",
    "for key,val in sample_count.items():\n",
    "    print(\"{:0.2f}% of the movies are {}\".format(100*val/len(sample_df), key))\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1) \n",
    "ax.bar(range(len(sample_count.keys())), list(sample_count.values()))\n",
    "ax.set_xticks(range(len(sample_count.keys())))\n",
    "ax.set_xticklabels(list(sample_count.keys()), rotation='vertical', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of Genres - imbalanced \n",
    "count_dict_norm = defaultdict(int)\n",
    "\n",
    "def dict_count(row, count_dict):\n",
    "    for genre in row:\n",
    "        count_dict[genre] += 1\n",
    "\n",
    "        \n",
    "count_dict_series = train_set[\"list_genres_consol\"].apply(lambda row: dict_count(row, count_dict_norm))\n",
    "\n",
    "sorted(count_dict_norm.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_w_replacement(df, genre_counts):\n",
    "    \"\"\"There can be duplicates within genre samples, but not across genre samples\"\"\"\n",
    "    max_records = sorted(genre_counts.items(), key=operator.itemgetter(1))[0][1] #num records for min class\n",
    "    new_df = pd.DataFrame(columns=list(data.columns))\n",
    "    for i in list(genre_counts.keys()):\n",
    "        print(i)\n",
    "        sample_df = df[df[\"list_genres_consol\"].apply(lambda x: str(i) in x)]\n",
    "        new_df = new_df.append(sample_df.sample(max_records, replace = True))\n",
    "        df = df[~df[\"list_genres_consol\"].apply(lambda x: str(i) in x)]\n",
    "    return new_df.sample(frac=1) #shuffles the sample dataframe\n",
    "\n",
    "def undersample_w_out_replacement(df, genre_counts):\n",
    "    \"\"\"There can be duplicates across genre samples, but not within genre samples\"\"\"\n",
    "    max_records = sorted(genre_counts.items(), key=operator.itemgetter(1))[0][1] #num records for min class\n",
    "    new_df = pd.DataFrame(columns=list(data.columns))\n",
    "    for i in list(genre_counts.keys()):\n",
    "        print(i)\n",
    "        sample_df = df[df[\"list_genres_consol\"].apply(lambda x: str(i) in x)]\n",
    "        new_df = new_df.append(sample_df.sample(max_records, replace = False))\n",
    "    return new_df.sample(frac=1) #shuffles the sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "new_train = undersample_w_out_replacement(train_set, count_dict_norm)\n",
    "end = time.time()\n",
    "print(\"total time: \", end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample without replacement - more balanced\n",
    "count_dict_undersample_w_out_replacement = defaultdict(int)\n",
    "count_val_series_2 = new_train[\"list_genres_consol\"].apply(lambda row: dict_count(row, count_dict_undersample_w_out_replacement))\n",
    "count_dict_undersample_w_out_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1) \n",
    "ax.bar(range(len(count_dict_undersample_w_out_replacement.keys())), list(count_dict_undersample_w_out_replacement.values()))\n",
    "ax.set_xticks(range(len(count_dict_undersample_w_out_replacement.keys())))\n",
    "ax.set_xticklabels(list(count_dict_undersample_w_out_replacement.keys()), rotation='vertical', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample with replacement - even more balanced but less variance within genres \n",
    "start = time.time()\n",
    "new_train = undersample_w_replacement(train_set, count_dict_norm)\n",
    "end = time.time()\n",
    "print(\"total time: \", end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict_undersample_w_replacement = defaultdict(int)\n",
    "count_val_series_2 = new_train[\"list_genres_consol\"].apply(lambda row: dict_count(row, count_dict_undersample_w_replacement))\n",
    "count_dict_undersample_w_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1) \n",
    "ax.bar(range(len(count_dict_undersample_w_replacement.keys())), list(count_dict_undersample_w_replacement.values()))\n",
    "ax.set_xticks(range(len(count_dict_undersample_w_replacement.keys())))\n",
    "ax.set_xticklabels(list(count_dict_undersample_w_replacement.keys()), rotation='vertical', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(full_data[\"list_genres_consol\"])\n",
    "\n",
    "MAX_NB_WORDS = 80000\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train_set['flattened_tokens'])\n",
    "\n",
    "# tokenizer.fit_on_texts(sample_df['flattened_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 80000)\n",
      "(22206, 80000)\n",
      "(22431, 80000)\n"
     ]
    }
   ],
   "source": [
    "x_train_bow = tokenizer.texts_to_matrix(train_set[\"flattened_tokens\"], mode=\"tfidf\")\n",
    "print(x_train_bow.shape)\n",
    "x_dev_bow = tokenizer.texts_to_matrix(dev_set[\"flattened_tokens\"], mode=\"tfidf\")\n",
    "print(x_dev_bow.shape)\n",
    "x_test_bow = tokenizer.texts_to_matrix(test_set[\"flattened_tokens\"], mode = \"tfidf\")\n",
    "print(x_test_bow.shape)\n",
    "\n",
    "# x_train_bow = tokenizer.texts_to_matrix(sample_df[\"flattened_tokens\"], mode=\"tfidf\")\n",
    "# print(x_train_bow.shape)\n",
    "# x_dev_bow = tokenizer.texts_to_matrix(dev_set[\"flattened_tokens\"], mode=\"tfidf\")\n",
    "# print(x_dev_bow.shape)\n",
    "# x_test_bow = tokenizer.texts_to_matrix(test_set[\"flattened_tokens\"], mode = \"tfidf\")\n",
    "# print(x_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.5243 - acc: 0.7640\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.3508 - acc: 0.8893\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 41s 819us/step - loss: 0.3029 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 41s 827us/step - loss: 0.2714 - acc: 0.9098\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 0.2455 - acc: 0.9197\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 39s 790us/step - loss: 0.2265 - acc: 0.9279\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 39s 784us/step - loss: 0.2115 - acc: 0.9341\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 40s 792us/step - loss: 0.1972 - acc: 0.9402\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 40s 796us/step - loss: 0.1864 - acc: 0.9441\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1759 - acc: 0.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5de6ae0278>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BoW TFIDF \n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(x_train_bow.shape[1],), activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(mlb.classes_.shape[0], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model\n",
    "\n",
    "#----Single Dataset to fit----\n",
    "# model.fit(x_train_bow, np.stack(sample_df[\"binarized_labels\"]), epochs = 10, batch_size = 10000)\n",
    "model.fit(x_train_bow, np.stack(train_set[\"binarized_labels\"]), epochs = 10, batch_size = 10000)\n",
    "\n",
    "#----Multiple Datasets (Over/UnderSampling)---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_dev_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save(\"BOW_tfidf_50dim_10kbatch_dropout_oversample.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previously stored models if desired\n",
    "\n",
    "# model = load_model('BOW_tfidf_100dim_10kbatch.h5')\n",
    "# preds = model.predict(x_dev_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiv_class_scores(y_true, y_pred, threshold, metric = None):\n",
    "    max_pred = np.array(y_pred.max(axis = 1)).reshape(-1,1)\n",
    "    \n",
    "    #Cant predict 0 for all classes - pick max val as label if all preds below threshold\n",
    "    for i in range(len(max_pred)): \n",
    "        if max_pred[i] > threshold:\n",
    "            max_pred[i] = threshold\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    y_pred = y_pred >= max_pred\n",
    "    \n",
    "    for i in range(len(mlb.classes_)):\n",
    "        if metric == \"precision\":\n",
    "            score = precision_score(y_true[:,i], y_pred[:,i])\n",
    "            print(\"The {} for {} is {}\".format(metric, mlb.classes_[i], score))\n",
    "        elif metric == \"recall\":\n",
    "            score = recall_score(y_true[:,i], y_pred[:,i])\n",
    "            print(\"The {} for {} is {}\".format(metric, mlb.classes_[i], score))\n",
    "        elif metric == \"f1\":\n",
    "            score = f1_score(y_true[:,i], y_pred[:,i])\n",
    "            print(\"The {} for {} is {}\".format(metric, mlb.classes_[i], score))\n",
    "        else:\n",
    "            return \"Not a valid metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for Action is 0.46673189823874756\n",
      "The precision for Adventure is 0.43405051449953225\n",
      "The precision for Comedy is 0.7043274853801169\n",
      "The precision for Crime is 0.3385636692818346\n",
      "The precision for Drama is 0.8367067833698031\n",
      "The precision for Family is 0.3665276329509906\n",
      "The precision for Horror is 0.4794238683127572\n",
      "The precision for Romance is 0.355225585379783\n",
      "The precision for Sci-Fi is 0.44097995545657015\n",
      "The precision for Thriller is 0.34363411619283063\n",
      "The recall for Action is 0.3835946924004825\n",
      "The recall for Adventure is 0.25806451612903225\n",
      "The recall for Comedy is 0.4259442636865186\n",
      "The recall for Crime is 0.3009656652360515\n",
      "The recall for Drama is 0.26535392088827203\n",
      "The recall for Family is 0.3354007633587786\n",
      "The recall for Horror is 0.5901722391084093\n",
      "The recall for Romance is 0.22817314746881878\n",
      "The recall for Sci-Fi is 0.5347738014854828\n",
      "The recall for Thriller is 0.1969535954658165\n",
      "The f1 for Action is 0.42109909512248944\n",
      "The f1 for Adventure is 0.32368329264039064\n",
      "The f1 for Comedy is 0.5308533145275036\n",
      "The f1 for Crime is 0.3186594717409827\n",
      "The f1 for Drama is 0.40292413066385663\n",
      "The f1 for Family is 0.3502740408570005\n",
      "The f1 for Horror is 0.5290644868301544\n",
      "The f1 for Romance is 0.27786464150100515\n",
      "The f1 for Sci-Fi is 0.48336893500152583\n",
      "The f1 for Thriller is 0.2503940553929295\n"
     ]
    }
   ],
   "source": [
    "indiv_class_scores(np.stack(dev_set[\"binarized_labels\"]), preds, threshold = 0.5, metric = \"precision\")\n",
    "indiv_class_scores(np.stack(dev_set[\"binarized_labels\"]), preds, threshold=0.5, metric = \"recall\")\n",
    "indiv_class_scores(np.stack(dev_set[\"binarized_labels\"]), preds, threshold= 0.5, metric= \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The micro precision is 0.8074074074074075\n",
      "The weighted macro precision is 0.8204505813639429\n",
      "The micro recall is 0.051693354907102605\n",
      "The weighted macro recall is 0.051693354907102605\n",
      "The micro f1 is 0.09716577960724679\n",
      "The weighted macro f1 is 0.09160909217793653\n"
     ]
    }
   ],
   "source": [
    "y_pred = preds >= 0.5\n",
    "micro_precision = precision_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'micro')\n",
    "weighted_macro_precision = precision_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'weighted')\n",
    "micro_recall = recall_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'micro')\n",
    "weighted_macro_recall = recall_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'weighted')\n",
    "micro_f1 = f1_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'micro')\n",
    "weighted_macro_f1 = f1_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'weighted')\n",
    "print(\"The micro precision is\", micro_precision)\n",
    "print(\"The weighted macro precision is\", weighted_macro_precision)\n",
    "print(\"The micro recall is\", micro_recall)\n",
    "print(\"The weighted macro recall is\", weighted_macro_recall)\n",
    "print(\"The micro f1 is\", micro_f1)\n",
    "print(\"The weighted macro f1 is\", weighted_macro_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_pr(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(len(mlb.classes_)):\n",
    "        p, r, d = precision_recall_curve(y_true[:,i], y_pred[:,i])\n",
    "        score = auc(r,p)\n",
    "        scores.append(score)\n",
    "        print(\"The AUC for {} is {}\".format(mlb.classes_[i], score))\n",
    "    macro_score = np.mean(scores)\n",
    "    y_true_raveled = np.ravel(y_true)\n",
    "    y_pred_raveled = np.ravel(y_pred)\n",
    "    p, r, d = precision_recall_curve(y_true_raveled, y_pred_raveled)\n",
    "    micro_score = auc(r,p)\n",
    "    print(\"The micro-avg AUC is {}\".format(micro_score))\n",
    "    print(\"The macro-avg AUC is {}\".format(macro_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for Action is 0.4404298166696471\n",
      "The AUC for Adventure is 0.30503119881870777\n",
      "The AUC for Comedy is 0.6685707522569782\n",
      "The AUC for Crime is 0.292850583480725\n",
      "The AUC for Drama is 0.7334506500910531\n",
      "The AUC for Family is 0.33637495237237464\n",
      "The AUC for Horror is 0.5651785413887016\n",
      "The AUC for Romance is 0.2684617119448543\n",
      "The AUC for Sci-Fi is 0.5241379554589547\n",
      "The AUC for Thriller is 0.23545241323700378\n",
      "The micro-avg AUC is 0.4483413542011898\n",
      "The macro-avg AUC is 0.43699385757190007\n"
     ]
    }
   ],
   "source": [
    "auc_pr(np.stack(dev_set[\"binarized_labels\"]), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW-Neural sum of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEmbed(file):\n",
    "    start = time.time()\n",
    "    print(\"Loading Embeddings\")\n",
    "    f = open(file, 'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    status_every = 100000\n",
    "    for i, line in enumerate(f):\n",
    "        if i%status_every == 0:\n",
    "            print('Processing line {:,}'.format(i))\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",'{:,}'.format(len(model)),\" words loaded!\")\n",
    "    end = time.time()\n",
    "    print(\"Total Time to load embeddings:\", end - start, \"seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOO LARGE TO PUSH TO GIT, DOWNLOAD SEPARATLEY FROM https://github.com/stanfordnlp/GloVe\n",
    "glove_dir = './glove.6B/'\n",
    "glove_filename = 'glove.6B.300d.txt'\n",
    "glove_fullpath = glove_dir + glove_filename\n",
    "glove_dd = loadEmbed(glove_fullpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Full Data and Generate Embeddings for BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"plot_lengths\"] = full_data[\"flattened_tokens\"].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(full_data[\"plot_lengths\"],75))\n",
    "plt.hist(full_data[\"plot_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_plot_BOW(plot):\n",
    "    word_embeddings = np.array([glove_dd.get(word, glove_dd.get(\"unk\")) for word in plot]).astype(np.float32)\n",
    "    sentence_embedding = [sum(dim) for dim in zip(*word_embeddings)]\n",
    "    return np.array(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embedding plots...\")\n",
    "start = time.time()\n",
    "full_data[\"flattened_embeddings\"] = full_data[\"flattened_tokens\"].apply(lambda row: embed_plot_BOW(row))\n",
    "end = time.time()\n",
    "print(\"Total Time to embed plots:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_data.to_pickle(\"./full_data_w_flattened_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_data = pd.read_pickle(\"./full_data_w_flattened_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_sample = full_data.iloc[0:2] #sample to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(full_data, test_size=0.10, random_state=42)\n",
    "\n",
    "#Separate training set into train and dev. Roughly 80% of original data is train, 10% dev, 10% test\n",
    "train_set, dev_set = train_test_split(train_set, test_size=0.11, random_state=42)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(full_data[\"list_genres_consol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow_embed = np.stack(train_set[\"flattened_embeddings\"])\n",
    "#y_train = np.stack(y_train.values)\n",
    "x_dev_bow_embed = np.stack(dev_set[\"flattened_embeddings\"])\n",
    "#y_test = np.stack(y_test.values)\n",
    "x_test_bow_embed = np.stack(test_set[\"flattened_embeddings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bow_embed = Sequential()\n",
    "model_bow_embed.add(Dense(100, input_shape=(x_train_bow_embed[1],), activation='tanh'))\n",
    "model_bow_embed.add(Dropout(0.5))\n",
    "model_bow_embed.add(Dense(mlb.classes_.shape[0], activation='sigmoid'))\n",
    "model_bow_embed.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
    "model_bow_embed.fit(x_train_bow_embed, np.stack(train_set[\"binarized_labels\"]), epochs = 10, batch_size = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_bow_embed = model_bow_embed.predict(x_dev_bow_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_class_scores(np.stack(dev_set[\"binarized_labels\"]), preds, threshold = 0.5, metric = \"precision\")\n",
    "indiv_class_scores(np.stack(dev_set[\"binarized_labels\"]), preds, threshold=0.5, metric = \"recall\")\n",
    "indiv_class_scores(np.stack(dev_set[\"binarized_labels\"]), preds, threshold= 0.5, metric= \"f1\")\n",
    "\n",
    "y_pred = preds_bow_embed >= 0.5\n",
    "micro_precision = precision_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'micro')\n",
    "weighted_macro_precision = precision_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'weighted')\n",
    "micro_recall = recall_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'micro')\n",
    "weighted_macro_recall = recall_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'weighted')\n",
    "micro_f1 = f1_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'micro')\n",
    "weighted_macro_f1 = f1_score(np.stack(dev_set[\"binarized_labels\"]), y_pred, average = 'weighted')\n",
    "print(\"The micro precision is\", micro_precision)\n",
    "print(\"The weighted macro precision is\", weighted_macro_precision)\n",
    "print(\"The micro recall is\", micro_recall)\n",
    "print(\"The weighted macro recall is\", weighted_macro_recall)\n",
    "print(\"The micro f1 is\", micro_f1)\n",
    "print(\"The weighted macro f1 is\", weighted_macro_f1)\n",
    "\n",
    "auc_pr(np.stack(dev_set[\"binarized_labels\"]), preds_bow_embed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI_DIRECTIONAL LSTM -- IGNORE EVERYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(\"embed_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 80000\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_SENT_LENGTH = 15\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=75,\n",
    "                            embeddings_regularizer=l2_reg,\n",
    "                            mask_zero = True, #determines whether masking is performed, i.e. whether the layers ignore the padded zeros in shorter documents\n",
    "                            trainable=False) \n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS+1, oov_token='UNK')\n",
    "tokenizer.fit_on_texts(full_data['flattened_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTS = 5\n",
    "data = np.zeros((len(full_data), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "doc_lst = []\n",
    "\n",
    "# keep the MAX_NB_WORDS most frequent words and replace the rest with 'UNK'\n",
    "# truncate to the first MAX_SENTS sentences per doc and MAX_SENT_LENGTH words per sentence\n",
    "\n",
    "for summary_num, row in full_data.iterrows():\n",
    "    for sent_num, sent in enumerate(row['tokenized_words']):\n",
    "        if sent_num < MAX_SENTS:\n",
    "            #wordTokens = text_to_word_sequence(sent)\n",
    "            word_num = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(sent):\n",
    "                if word_num < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] <= MAX_NB_WORDS):\n",
    "                        data[summary_num, sent_num, word_num] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data[summary_num, sent_num, word_num] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    word_num = word_num + 1\n",
    "            doc_lst.append(words_in_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_plot_data = data.reshape(len(full_data), -1) #collapse sentence length and max sents into single dimension\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(lstm_plot_data, \n",
    "                                                    full_data[\"binarized_labels\"], test_size=0.20, random_state=42)\n",
    "\n",
    "# X_train_lstm = np.stack(X_train_lstm.values)\n",
    "y_train_lstm = np.stack(y_train_lstm.values)\n",
    "# X_test_lstm = np.stack(X_test_lstm.values)\n",
    "y_test_lstm = np.stack(y_test_lstm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X_train_lstm.shape[1],), dtype='int32')\n",
    "embedded_plot = embedding_layer(input_layer)\n",
    "bilstm_layer = Bidirectional(LSTM(100))(embedded_plot)\n",
    "output_layer = Dense(units=mlb.classes_.shape[0], activation=\"sigmoid\")(bilstm_layer)\n",
    "LSTM_model = Model(inputs=input_layer, outputs= output_layer)\n",
    "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
    "LSTM_model.fit(X_train_lstm, y_train_lstm, epochs = 1, batch_size = 100)\n",
    "preds_LSTM = LSTM_model.predict(X_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_class_scores(y_test_lstm, preds_LSTM, threshold = 0.5, metric = \"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_class_scores(y_test_lstm, preds_LSTM, threshold = 0.5, metric = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_class_scores(y_test_lstm, preds_LSTM, threshold = 0.5, metric = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LSTM = preds_LSTM >= 0.5\n",
    "micro_precision = precision_score(y_test_lstm, y_pred_LSTM, average = 'micro')\n",
    "weighted_macro_precision = precision_score(y_test_lstm, y_pred_LSTM, average = 'weighted')\n",
    "micro_recall = recall_score(y_test_lstm, y_pred_LSTM, average = 'micro')\n",
    "weighted_macro_recall = recall_score(y_test_lstm, y_pred_LSTM, average = 'weighted')\n",
    "micro_f1 = f1_score(y_test_lstm, y_pred_LSTM, average = 'micro')\n",
    "weighted_macro_f1 = f1_score(y_test_lstm, y_pred_LSTM, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The micro precision is\", micro_precision)\n",
    "print(\"The weighted macro precision is\", weighted_macro_precision)\n",
    "print(\"The micro recall is\", micro_recall)\n",
    "print(\"The weighted macro recall is\", weighted_macro_recall)\n",
    "print(\"The micro f1 is\", micro_f1)\n",
    "print(\"The weighted macro f1 is\", weighted_macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
