{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhil.patel1896/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle as pkl\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers, regularizers, optimizers\n",
    "from keras.callbacks import History, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in train and test txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_genres = open(\"train_genres.txt\", encoding=\"utf-8\").read().split('\\n')\n",
    "train_plots = open(\"train_plots.txt\", encoding=\"utf-8\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({\"genres\": train_genres, \"plots\": train_plots})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventure', 'Animation', 'Comedy', '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[4][\"genres\"].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_genres = open(\"test_genres.txt\", encoding=\"utf-8\").read().split('\\n')\n",
    "test_plots = open(\"test_plots.txt\", encoding=\"utf-8\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({\"genres\": test_genres, \"plots\": test_plots})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat dataframes\n",
    "full_data = pd.concat([train_data, test_data], ignore_index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRIEF EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert genres to list for easier analysis\n",
    "def list_genres(row):\n",
    "    return row[\"genres\"].split(\" \")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"list_genres\"] = full_data.apply(lambda row: list_genres(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count num of movies per genre\n",
    "def dict_count(row):\n",
    "    global count_dict\n",
    "    for genre in row[\"list_genres\"]:\n",
    "        count_dict[genre] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ONLY ONCE!!!\n",
    "count_val_series = full_data.apply(lambda row: dict_count(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.88% of the movies are Comedy\n",
      "45.84% of the movies are Drama\n",
      "2.37% of the movies are Western\n",
      "7.00% of the movies are Adventure\n",
      "6.21% of the movies are Animation\n",
      "9.71% of the movies are Action\n",
      "11.18% of the movies are Thriller\n",
      "8.08% of the movies are Family\n",
      "11.01% of the movies are Romance\n",
      "5.89% of the movies are Fantasy\n",
      "7.77% of the movies are Horror\n",
      "4.77% of the movies are History\n",
      "4.95% of the movies are Music\n",
      "5.60% of the movies are Sci-Fi\n",
      "2.85% of the movies are War\n",
      "7.27% of the movies are Crime\n",
      "2.23% of the movies are Musical\n",
      "5.18% of the movies are Biography\n",
      "5.40% of the movies are Mystery\n",
      "2.37% of the movies are Sport\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0,0,'Comedy'),\n",
       " Text(0,0,'Drama'),\n",
       " Text(0,0,'Western'),\n",
       " Text(0,0,'Adventure'),\n",
       " Text(0,0,'Animation'),\n",
       " Text(0,0,'Action'),\n",
       " Text(0,0,'Thriller'),\n",
       " Text(0,0,'Family'),\n",
       " Text(0,0,'Romance'),\n",
       " Text(0,0,'Fantasy'),\n",
       " Text(0,0,'Horror'),\n",
       " Text(0,0,'History'),\n",
       " Text(0,0,'Music'),\n",
       " Text(0,0,'Sci-Fi'),\n",
       " Text(0,0,'War'),\n",
       " Text(0,0,'Crime'),\n",
       " Text(0,0,'Musical'),\n",
       " Text(0,0,'Biography'),\n",
       " Text(0,0,'Mystery'),\n",
       " Text(0,0,'Sport')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count num of movies per genre\n",
    "for key,val in count_dict.items():\n",
    "    print(\"{:0.2f}% of the movies are {}\".format(100*val/len(full_data), key))\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1) \n",
    "ax.bar(range(len(count_dict.keys())), list(count_dict.values()))\n",
    "ax.set_xticks(range(len(count_dict.keys())))\n",
    "ax.set_xticklabels(list(count_dict.keys()), rotation='vertical', fontsize=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg num of genres: 1.835858872086706\n",
      "Median num of genres: 1.0\n",
      "Max number of genres: 11\n",
      "Min number of genres: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.29306e+05, 6.44310e+04, 4.38940e+04, 1.29500e+04, 3.96000e+03,\n",
       "        1.01100e+03, 2.36000e+02, 5.20000e+01, 6.00000e+00, 7.00000e+00]),\n",
       " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Number of genres per movie\n",
    "genre_labels = full_data[\"list_genres\"].str.len()\n",
    "print(\"Avg num of genres:\", np.mean(genre_labels))\n",
    "print(\"Median num of genres:\", np.median(genre_labels))\n",
    "print(\"Max number of genres:\", np.max(genre_labels))\n",
    "print(\"Min number of genres:\", np.min(genre_labels))\n",
    "\n",
    "\n",
    "plt.hist(genre_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of characters in a summary is 458.48165446888345, max is 1192\n"
     ]
    }
   ],
   "source": [
    "#average length of plot summary (characters)\n",
    "avg_num_chars = train_data[\"plots\"].str.len().mean()\n",
    "max_num_chars = train_data[\"plots\"].str.len().max()\n",
    "print(f'The average number of characters in a summary is {avg_num_chars}, max is {max_num_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of words in a summary is 79.8617855991245, max is 195\n",
      "The average number of sentences in a summary is 4.39193969181462, max is 74\n",
      "18.18371635383909\n"
     ]
    }
   ],
   "source": [
    "avg_num_words = train_data[\"plots\"].str.count(\" \").mean() + 1\n",
    "max_num_words = train_data[\"plots\"].str.count(\" \").max() + 1\n",
    "avg_num_periods = train_data[\"plots\"].str.count(\"[\\.\\?!]\").mean()\n",
    "max_num_periods = train_data[\"plots\"].str.count(\"[\\.\\?!]\").max()\n",
    "print(f'The average number of words in a summary is {avg_num_words}, max is {max_num_words}')\n",
    "print(f'The average number of sentences in a summary is {avg_num_periods}, max is {max_num_periods}')\n",
    "print(avg_num_words/avg_num_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"plots\"].str.count(\"\\n\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.86194193920325\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "#Alternative way to calculate plot length\n",
    "print(train_data[\"plots\"].str.lower().str.split().str.len().mean()) #Avg words\n",
    "print(train_data[\"plots\"].str.lower().str.split().str.len().max()) #Max words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567468\n",
      "16346270\n"
     ]
    }
   ],
   "source": [
    "dict_words = Counter(\" \".join(train_data[\"plots\"]).split(\" \"))\n",
    "print(len(dict_words.keys())) #should be number of unique words\n",
    "print(sum(dict_words.values())) #should be total number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/akhil.patel1896/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/akhil.patel1896/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Lemmetizing Function\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def nltk2wn_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize w/lemmetization AFTER removing stopwords \n",
    "#https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "def tokenize(plot, stop_words, lemmatize = False):\n",
    "    \n",
    "    def re_sub(pattern, replace):\n",
    "        return re.sub(pattern, replace, plot)\n",
    "    \n",
    "    plot = plot.lower() #lowercase\n",
    "    plot = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,/.\\d]*\", \"DG\") #generic tag for numbers\n",
    "    plot = re_sub(r\"([!?.]){2,}\", r\"\\1\") #Convert multiple punctuations to the last punctuation mark\n",
    "    plot = plot.replace('-',' ') #separating hyphenated words\n",
    "    plot = plot.replace('_','') #remove underscores\n",
    "    plot = re_sub(r'(?<!\\w)([a-zA-Z])\\.', r'\\1') #remove periods from abbreviations\n",
    "    plot = re_sub('[^\\w\\s\\.\\?\\!\\']','') #remove punctuation besides sentence completers and apostrophes\n",
    "    sentences = nltk.sent_tokenize(plot)\n",
    "    words = list(map(nltk.word_tokenize, sentences))\n",
    "    words = [[x for x in w if not x in stop_words] for w in words]\n",
    "\n",
    "    if lemmatize:\n",
    "        output_lem = [nltk.pos_tag(w) for w in words]\n",
    "        return [[lemmatizer.lemmatize(x[0], pos = nltk2wn_tag(x[1])) for x in w] for w in output_lem]\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/akhil.patel1896/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/akhil.patel1896/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time to tokenize plots: 1484.1539039611816 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "full_data['tokenized_words'] = full_data.apply(lambda row: tokenize(row['plots'], stop, lemmatize = True), axis=1)\n",
    "end = time.time()\n",
    "print(\"Total Time to tokenize plots:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['flattened_tokens'] = full_data.apply(lambda l: [item for sublist in l['tokenized_words'] for item in sublist], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(full_data[\"list_genres\"])\n",
    "full_data[\"binarized_labels\"] = labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
       "       'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music',\n",
       "       'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Sport', 'Thriller',\n",
       "       'War', 'Western'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255853, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_pickle(\"./full_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_pickle(\"./full_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>plots</th>\n",
       "      <th>list_genres</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>flattened_tokens</th>\n",
       "      <th>binarized_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>A stranded theatrical troupe manages to get ba...</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[[stranded, theatrical, troupe, manages, get, ...</td>\n",
       "      <td>[stranded, theatrical, troupe, manages, get, b...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama</td>\n",
       "      <td>While waiting at the bus stop for the woman he...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[[wait, bus, stop, woman, intend, marry, jay, ...</td>\n",
       "      <td>[wait, bus, stop, woman, intend, marry, jay, d...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Western</td>\n",
       "      <td>A dissatisfied ranch hand becomes a bounty hun...</td>\n",
       "      <td>[Western]</td>\n",
       "      <td>[[dissatisfied, ranch, hand, become, bounty, h...</td>\n",
       "      <td>[dissatisfied, ranch, hand, become, bounty, hu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drama</td>\n",
       "      <td>Policeman Lasse rehabilitates young prisoners ...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[[policeman, lasse, rehabilitate, young, priso...</td>\n",
       "      <td>[policeman, lasse, rehabilitate, young, prison...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adventure Animation Comedy</td>\n",
       "      <td>Patricia and Isobelle O'Sullivan arrives at th...</td>\n",
       "      <td>[Adventure, Animation, Comedy]</td>\n",
       "      <td>[[patricia, isobelle, o'sullivan, arrive, st.,...</td>\n",
       "      <td>[patricia, isobelle, o'sullivan, arrive, st., ...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        genres  \\\n",
       "0                      Comedy    \n",
       "1                       Drama    \n",
       "2                     Western    \n",
       "3                       Drama    \n",
       "4  Adventure Animation Comedy    \n",
       "\n",
       "                                               plots  \\\n",
       "0  A stranded theatrical troupe manages to get ba...   \n",
       "1  While waiting at the bus stop for the woman he...   \n",
       "2  A dissatisfied ranch hand becomes a bounty hun...   \n",
       "3  Policeman Lasse rehabilitates young prisoners ...   \n",
       "4  Patricia and Isobelle O'Sullivan arrives at th...   \n",
       "\n",
       "                      list_genres  \\\n",
       "0                        [Comedy]   \n",
       "1                         [Drama]   \n",
       "2                       [Western]   \n",
       "3                         [Drama]   \n",
       "4  [Adventure, Animation, Comedy]   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  [[stranded, theatrical, troupe, manages, get, ...   \n",
       "1  [[wait, bus, stop, woman, intend, marry, jay, ...   \n",
       "2  [[dissatisfied, ranch, hand, become, bounty, h...   \n",
       "3  [[policeman, lasse, rehabilitate, young, priso...   \n",
       "4  [[patricia, isobelle, o'sullivan, arrive, st.,...   \n",
       "\n",
       "                                    flattened_tokens  \\\n",
       "0  [stranded, theatrical, troupe, manages, get, b...   \n",
       "1  [wait, bus, stop, woman, intend, marry, jay, d...   \n",
       "2  [dissatisfied, ranch, hand, become, bounty, hu...   \n",
       "3  [policeman, lasse, rehabilitate, young, prison...   \n",
       "4  [patricia, isobelle, o'sullivan, arrive, st., ...   \n",
       "\n",
       "                                    binarized_labels  \n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over tokenized words and create dictionaries that keep track of number of tokens, length of sentences, and sentences per plot summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255853\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "sent_per_summary_dict = {}\n",
    "word_per_sent_dict = {}\n",
    "rows = len(full_data['tokenized_words'])\n",
    "print(rows)#number of plot summaries\n",
    "for i in range(len(full_data['tokenized_words'])):\n",
    "    length = len(full_data['tokenized_words'][i])\n",
    "    if length in sent_per_summary_dict:\n",
    "        sent_per_summary_dict[length] += 1\n",
    "    else:\n",
    "        sent_per_summary_dict[length] = 1\n",
    "    for j in range(length):\n",
    "        word_count = len(full_data['tokenized_words'][i][j])\n",
    "        if word_count in word_per_sent_dict:\n",
    "            word_per_sent_dict[word_count] += 1\n",
    "        else:\n",
    "            word_per_sent_dict[word_count] = 1\n",
    "        for word in full_data['tokenized_words'][i][j]:\n",
    "            if word in word_dict:\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244947\n",
      "12584868\n"
     ]
    }
   ],
   "source": [
    "print(len(word_dict.keys())) #should be number of unique words\n",
    "print(sum(word_dict.values())) #should be total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114657\n",
      "80476\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "twoOrOne = 0\n",
    "for value in word_dict.values():\n",
    "    if value == 1:\n",
    "        count +=1\n",
    "    if value <3:\n",
    "        twoOrOne +=1\n",
    "print(len(word_dict.keys()) - count) # words that appear more than once\n",
    "print(len(word_dict.keys()) - twoOrOne) # words that appear more than twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "1016033\n",
      "148\n",
      "12.386278792125847\n"
     ]
    }
   ],
   "source": [
    "print(len(word_per_sent_dict.keys())) #should be number of unique sentence lengths\n",
    "print(sum(word_per_sent_dict.values())) #should be number of sentences in all plots\n",
    "print(max(word_per_sent_dict.keys())) #should be largest sentence length\n",
    "total = 0\n",
    "weight_sum = 0\n",
    "for key, value in word_per_sent_dict.items():\n",
    "    total += value\n",
    "    weight_sum += key*value\n",
    "print(weight_sum/total) #should be average sentence length\n",
    "#print(word_per_sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "28\n",
      "3.971159220333551\n"
     ]
    }
   ],
   "source": [
    "print(len(sent_per_summary_dict.keys())) #should be number of unique sentence lengths per summary\n",
    "print(max(sent_per_summary_dict.keys())) #should be highest amount of sentences per summary\n",
    "total = 0\n",
    "weight_sum = 0\n",
    "for key, value in sent_per_summary_dict.items():\n",
    "    total += value\n",
    "    weight_sum += key*value\n",
    "print(weight_sum/total) #should be average sentence count per summary\n",
    "#print(sent_per_summary_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GloVe Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#compute an index mapping words to known embeddings, by parsing the data dump of pre-trained embeddings\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create average word vector. This will later be used in place of unknown words\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        pass\n",
    "n_vec = i + 1\n",
    "hidden_dim = len(line.split(' ')) - 1\n",
    "\n",
    "vecs = np.zeros((n_vec, hidden_dim), dtype=np.float32)\n",
    "\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        vecs[i] = np.array([float(n) for n in line.split(' ')[1:]], dtype=np.float32)\n",
    "\n",
    "average_vec = np.mean(vecs, axis=0)\n",
    "#print(average_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above token analysis, we set the following hyperparameters at these initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 15 #Gets ~80% of sentences\n",
    "MAX_SENTS = 5 #Gets ~80% of summaries\n",
    "MAX_NB_WORDS = 80000 #Eliminates words seen two or fewer times\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(full_data['flattened_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((len(full_data), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "doc_lst = []\n",
    "\n",
    "# keep the MAX_NB_WORDS most frequent words and replace the rest with 'UNK'\n",
    "# truncate to the first MAX_SENTS sentences per doc and MAX_SENT_LENGTH words per sentence\n",
    "\n",
    "for summary_num, row in full_data.iterrows():\n",
    "    for sent_num, sent in enumerate(row['tokenized_words']):\n",
    "        if sent_num < MAX_SENTS:\n",
    "            word_num = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(sent):\n",
    "                if word_num < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data[summary_num, sent_num, word_num] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data[summary_num, sent_num, word_num] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    word_num = word_num + 1\n",
    "            doc_lst.append(words_in_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 244947 unique tokens.\n",
      "Shape of data tensor: (255853, 5, 15)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66689\n",
      "1\n",
      "178257\n"
     ]
    }
   ],
   "source": [
    "#leverage our embedding_index dictionary and our word_index to compute our embedding matrix\n",
    "embedding_matrix = np.zeros((MAX_NB_WORDS+1, EMBEDDING_DIM))\n",
    "count = 0\n",
    "unknown =0\n",
    "added =0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    # words not found in embedding index will be all-zeros.\n",
    "    if embedding_vector is not None and i < MAX_NB_WORDS:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        added+=1\n",
    "    elif i == MAX_NB_WORDS:\n",
    "        # index MAX_NB_WORDS in data corresponds to 'UNK'\n",
    "        embedding_matrix[i] = average_vec #use average vector for unknown\n",
    "        unknown+=1\n",
    "    else:\n",
    "        count +=1\n",
    "print(added) #of the MAX_NB_WORDS most frequent tokens in our corpus, this many have GloVe embeddings\n",
    "print(unknown)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 127228 which is 51.94 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load this embedding matrix into an Embedding layer.\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            embeddings_regularizer=l2_reg,\n",
    "                            mask_zero = True, #determines whether masking is performed, i.e. whether the layers ignore the padded zeros in shorter documents\n",
    "                            trainable=False) #prevent weights from being updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length=MAX_SENT_LENGTH, \n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f\n",
    "# sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "# embedded_sequences = embedding_layer(sentence_input)\n",
    "# l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
    "# sentEncoder = Model(sentence_input, l_lstm)\n",
    "\n",
    "# review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n",
    "# review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "# l_lstm_sent = Bidirectional(LSTM(100))(review_encoder)\n",
    "# preds = Dense(20, activation='softmax')(l_lstm_sent)\n",
    "# model = Model(review_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Hsankesara/DeepResearch/blob/master/Hierarchical_Attention_Network/attention_with_context.py\n",
    "#https://medium.com/analytics-vidhya/hierarchical-attention-networks-d220318cf87e\n",
    "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words level attention model\n",
    "word_input = Input(shape=(MAX_SENT_LENGTH,), dtype='float32')\n",
    "word_sequences = embedding_layer(word_input)\n",
    "word_lstm = Bidirectional(LSTM(150, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "word_att = AttentionWithContext()(word_dense)\n",
    "wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "# Sentence level attention model\n",
    "sent_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='float32')\n",
    "sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "sent_lstm = Bidirectional(LSTM(150, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "sent_att = Dropout(0.5)(AttentionWithContext()(sent_dense))\n",
    "preds = Dense(20, activation='sigmoid')(sent_att)\n",
    "model = Model(sent_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 5, 15)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 5, 200)            24896600  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 5, 300)            421200    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 5, 200)            60200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                4020      \n",
      "=================================================================\n",
      "Total params: 25,422,420\n",
      "Trainable params: 927,620\n",
      "Non-trainable params: 24,494,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate training set into train and dev. Roughly 80% of original data is train, 10% dev, 10% test\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'han_food'\n",
    "history = History()\n",
    "csv_logger = CSVLogger('./{0}_{1}.log'.format(fname, REG_PARAM), separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204937, 5, 15)\n",
      "(204937, 20)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 445s - loss: 0.2093 - acc: 0.9214\n",
      "Epoch 2/10\n",
      " - 442s - loss: 0.1921 - acc: 0.9266\n",
      "Epoch 3/10\n",
      " - 445s - loss: 0.1852 - acc: 0.9289\n",
      "Epoch 4/10\n",
      " - 446s - loss: 0.1797 - acc: 0.9308\n",
      "Epoch 5/10\n",
      " - 444s - loss: 0.1743 - acc: 0.9327\n",
      "Epoch 6/10\n",
      " - 441s - loss: 0.1691 - acc: 0.9346\n",
      "Epoch 7/10\n",
      " - 442s - loss: 0.1639 - acc: 0.9365\n",
      "Epoch 8/10\n",
      " - 445s - loss: 0.1591 - acc: 0.9383\n",
      "Epoch 9/10\n",
      " - 440s - loss: 0.1547 - acc: 0.9400\n",
      "Epoch 10/10\n",
      " - 442s - loss: 0.1506 - acc: 0.9416\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, shuffle=False, \n",
    "          callbacks=[history, csv_logger], verbose=2)\n",
    "\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiv_class_scores(y_true, y_pred, threshold, metric = None):\n",
    "    y_pred = y_pred >= threshold\n",
    "    for i in range(len(mlb.classes_)):\n",
    "        if metric == \"precision\":\n",
    "            score = precision_score(y_true[:,i], y_pred[:,i])\n",
    "            print(\"The {} for {} is {}\".format(metric, mlb.classes_[i], score))\n",
    "        elif metric == \"recall\":\n",
    "            score = recall_score(y_true[:,i], y_pred[:,i])\n",
    "            print(\"The {} for {} is {}\".format(metric, mlb.classes_[i], score))\n",
    "        elif metric == \"f1\":\n",
    "            score = f1_score(y_true[:,i], y_pred[:,i])\n",
    "            print(\"The {} for {} is {}\".format(metric, mlb.classes_[i], score))\n",
    "        else:\n",
    "            return \"Not a valid metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for Action is 0.5720653789004457\n",
      "The precision for Adventure is 0.4880273660205245\n",
      "The precision for Animation is 0.6103542234332425\n",
      "The precision for Biography is 0.5144230769230769\n",
      "The precision for Comedy is 0.6710597580790757\n",
      "The precision for Crime is 0.489202657807309\n",
      "The precision for Drama is 0.6698410199905557\n",
      "The precision for Family is 0.5005336179295624\n",
      "The precision for Fantasy is 0.5359116022099447\n",
      "The precision for History is 0.48513302034428796\n",
      "The precision for Horror is 0.6481481481481481\n",
      "The precision for Music is 0.7553324968632371\n",
      "The precision for Musical is 0.47586206896551725\n",
      "The precision for Mystery is 0.3878504672897196\n",
      "The precision for Romance is 0.44787379972565156\n",
      "The precision for Sci-Fi is 0.6248736097067745\n",
      "The precision for Sport is 0.6442105263157895\n",
      "The precision for Thriller is 0.44640943193997856\n",
      "The precision for War is 0.5737051792828686\n",
      "The precision for Western is 0.8229665071770335\n"
     ]
    }
   ],
   "source": [
    "indiv_class_scores(y_dev, preds, threshold = 0.5, metric = \"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall for Action is 0.3200332502078138\n",
      "The recall for Adventure is 0.2505854800936768\n",
      "The recall for Animation is 0.4357976653696498\n",
      "The recall for Biography is 0.2471131639722864\n",
      "The recall for Comedy is 0.5244814448991111\n",
      "The recall for Crime is 0.3223864258347017\n",
      "The recall for Drama is 0.7350375680110545\n",
      "The recall for Family is 0.23206333498268183\n",
      "The recall for Fantasy is 0.19157340355497038\n",
      "The recall for History is 0.26956521739130435\n",
      "The recall for Horror is 0.41623578076525336\n",
      "The recall for Music is 0.4762658227848101\n",
      "The recall for Musical is 0.11876075731497418\n",
      "The recall for Mystery is 0.06207928197456993\n",
      "The recall for Romance is 0.23556998556998557\n",
      "The recall for Sci-Fi is 0.44048467569493943\n",
      "The recall for Sport is 0.534965034965035\n",
      "The recall for Thriller is 0.29125874125874124\n",
      "The recall for War is 0.4050632911392405\n",
      "The recall for Western is 0.6209386281588448\n"
     ]
    }
   ],
   "source": [
    "indiv_class_scores(y_dev, preds, threshold=0.5, metric = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 for Action is 0.41044776119402987\n",
      "The f1 for Adventure is 0.3311411992263056\n",
      "The f1 for Animation is 0.5085130533484676\n",
      "The f1 for Biography is 0.3338533541341654\n",
      "The f1 for Comedy is 0.588785046728972\n",
      "The f1 for Crime is 0.38865061035961723\n",
      "The f1 for Drama is 0.7009264978381717\n",
      "The f1 for Family is 0.31710615280594995\n",
      "The f1 for Fantasy is 0.28225024248302616\n",
      "The f1 for History is 0.34656232532140857\n",
      "The f1 for Horror is 0.5069269521410579\n",
      "The f1 for Music is 0.5841824357108201\n",
      "The f1 for Musical is 0.19008264462809915\n",
      "The f1 for Mystery is 0.10702772404900066\n",
      "The f1 for Romance is 0.3087470449172577\n",
      "The f1 for Sci-Fi is 0.5167224080267558\n",
      "The f1 for Sport is 0.5845272206303725\n",
      "The f1 for Thriller is 0.3525179856115108\n",
      "The f1 for War is 0.4748557295960429\n",
      "The f1 for Western is 0.7078189300411523\n"
     ]
    }
   ],
   "source": [
    "indiv_class_scores(y_dev, preds, threshold= 0.5, metric= \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = preds >= 0.5\n",
    "micro_precision = precision_score(y_dev, y_pred, average = 'micro')\n",
    "weighted_macro_precision = precision_score(y_dev, y_pred, average = 'weighted')\n",
    "micro_recall = recall_score(y_dev, y_pred, average = 'micro')\n",
    "weighted_macro_recall = recall_score(y_dev, y_pred, average = 'weighted')\n",
    "micro_f1 = f1_score(y_dev, y_pred, average = 'micro')\n",
    "weighted_macro_f1 = f1_score(y_dev, y_pred, average = 'weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The micro precision is 0.6150437213729106\n",
      "The weighted macro precision is 0.5905363071917877\n",
      "The micro recall is 0.44831548367515067\n",
      "The weighted macro recall is 0.44831548367515067\n",
      "The micro f1 is 0.5186086171440036\n",
      "The weighted macro f1 is 0.4956716066600087\n"
     ]
    }
   ],
   "source": [
    "print(\"The micro precision is\", micro_precision)\n",
    "print(\"The weighted macro precision is\", weighted_macro_precision)\n",
    "print(\"The micro recall is\", micro_recall)\n",
    "print(\"The weighted macro recall is\", weighted_macro_recall)\n",
    "print(\"The micro f1 is\", micro_f1)\n",
    "print(\"The weighted macro f1 is\", weighted_macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('HAN_10epochs.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
